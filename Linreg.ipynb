{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, dim):\n",
    "        self.dim = max(1, dim)\n",
    "        self.weights = np.zeros((1+dim,1))\n",
    "\n",
    "    def X_T(self,X):\n",
    "        num_examples = X.shape[0]\n",
    "        real_X = np.c_[np.ones(num_examples), X]\n",
    "        return real_X\n",
    "\n",
    "    def train(self,X,Y):\n",
    "        real_X = self.X_T(X)\n",
    "        pinv_X = np.linalg.pinv(real_X)\n",
    "        self.weights = np.dot(pinv_X,Y)\n",
    "        \n",
    "    def predict(self,X):\n",
    "        real_X = self.X_T(X)\n",
    "        h = np.matmul(real_X, self.weights)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLA:\n",
    "    def __init__(self, dim):\n",
    "        self.dim = dim\n",
    "        self.weights = np.zeros(1+dim)\n",
    "\n",
    "    def train(self,x,y):\n",
    "        guess = self.predict(x)\n",
    "        realx = np.append([1],x[:self.dim])\n",
    "        agreed = guess == y\n",
    "        if not agreed:\n",
    "            self.weights = self.weights + np.multiply(y,realx)\n",
    "        return agreed\n",
    "    \n",
    "    def predict(self,x):\n",
    "        realx = np.append([1],x[:self.dim])\n",
    "        h = np.dot(self.weights, realx)\n",
    "        return np.sign(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line:\n",
    "    def __init__(self, p1, p2):\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "        diff = np.subtract(p2, p1)\n",
    "        if diff[0] <= 0.00001:\n",
    "            self.m = None\n",
    "            self.vert = True\n",
    "        else:\n",
    "            self.m = diff[1]/diff[0]\n",
    "            self.vert = False\n",
    "        if not self.vert:\n",
    "            self.b = ((-1 * p1[1])/self.m) + p1[0]\n",
    "            \n",
    "    def label(self,testpt):\n",
    "        if self.vert == False:\n",
    "            line_y = self.m*testpt[0] + self.b\n",
    "            diff = testpt[1] - line_y\n",
    "        else:\n",
    "            line_x = self.p1[0]\n",
    "            diff = testpt[0] - line_x\n",
    "        return np.sign(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR_EXP:        \n",
    "    def __init__(self, numpoints):\n",
    "        self.n = numpoints\n",
    "        self.lr = LinearRegression(2)\n",
    "        self.points = np.random.uniform(-1.0,1.0,(self.n, 2))\n",
    "        self.p12 = [np.random.uniform(-1.0,1.0,2) for x in range(2)]\n",
    "        self.target = Line(self.p12[0],self.p12[1])\n",
    "        while self.p12[0][0] == self.p12[1][0] and self.p12[0][1] == self.p12[1][1]:\n",
    "            p12 = [np.random.uniform(-1.0,1.0,2) for x in range(2)]       \n",
    "        self.labels = np.array([self.target.label(x) for x in self.points])\n",
    "        \n",
    "    def train(self):\n",
    "        self.lr.train(self.points, self.labels)\n",
    "    #E_in(w) = (1/N)*L2norm(X*w-y)\n",
    "    \n",
    "    def Eout_points(self, numpoints):\n",
    "        self.n = numpoints\n",
    "        self.points = np.random.uniform(-1.0,1.0,(self.n, 2))\n",
    "        self.labels = np.array([self.target.label(x) for x in self.points])\n",
    "    \n",
    "    def e_in(self):\n",
    "        xw = self.lr.predict(self.points)\n",
    "        xw = np.sign(xw)\n",
    "        mydiff = np.not_equal(xw, self.labels)\n",
    "        e_in = np.mean(mydiff)\n",
    "        return e_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLA_EXP:        \n",
    "    def __init__(self, numpoints):\n",
    "        self.n = numpoints\n",
    "        self.points = [np.random.uniform(-1.0,1.0,2) for x in range(numpoints)]\n",
    "        p = [np.random.uniform(-1.0,1.0,2) for x in range(2)]\n",
    "        while p[0][0] == p[1][0] and p[0][1] == p[1][1]:\n",
    "            p = [np.random.uniform(-1.0,1.0,2) for x in range(2)]\n",
    "        self.target = Line(p[0],p[1])\n",
    "        self.PLA = PLA(2)\n",
    "\n",
    "    def agreement(self,point):\n",
    "        h_p = self.PLA.predict(point)\n",
    "        actval = self.target.label(point)\n",
    "        return h_p == actval\n",
    "\n",
    "    def iteration(self):\n",
    "        iters = 0\n",
    "        testidx = 0\n",
    "        while True:\n",
    "            actval = self.target.label(self.points[testidx])\n",
    "            success = self.PLA.train(self.points[testidx],actval)\n",
    "            if success:\n",
    "                allgood = True\n",
    "                for i in range(self.n):\n",
    "                    agree = self.agreement(self.points[i])\n",
    "                    if not agree:\n",
    "                        allgood = False\n",
    "                        break\n",
    "                if allgood:\n",
    "                    break\n",
    "            else:\n",
    "                iters = iters + 1\n",
    "            testidx = int(np.random.uniform(0, self.n-0.5))\n",
    "        return iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob5to7(num_exp):\n",
    "    nin = 100\n",
    "    nout = 1000\n",
    "    npla = 10\n",
    "    g_ein = np.array([])\n",
    "    g_eout = np.array([])\n",
    "    g_iters = np.array([])\n",
    "    \n",
    "    for i in range(num_exp):\n",
    "        h_lr = LR_EXP(nin)\n",
    "        h_lr.train()\n",
    "        \n",
    "        h_ein = h_lr.e_in()\n",
    "        g_ein = np.concatenate((g_ein,[h_ein]))\n",
    "        \n",
    "        h_lr.Eout_points(nout)\n",
    "        h_eout = h_lr.e_in()\n",
    "        g_eout = np.concatenate((g_eout,[h_eout]))\n",
    "        \n",
    "        h_pla = PLA_EXP(npla)\n",
    "        h_pla.target = h_lr.target\n",
    "        h_pla.PLA.weights = h_lr.lr.weights.T\n",
    "        h_iter = h_pla.iteration()\n",
    "        g_iters = np.concatenate((g_iters,[h_iter]))\n",
    "        \n",
    "    ein_avg = np.average(g_ein)\n",
    "    eout_avg = np.average(g_eout)\n",
    "    iters_avg = np.average(g_iters)\n",
    "    \n",
    "    print(\"e_in average:\",  ein_avg)\n",
    "    print(\"e_out average:\",  eout_avg)\n",
    "    print(\"perceptron convergence average:\",  iters_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_in average: 0.0286\n",
      "e_out average: 0.036950000000000004\n",
      "perceptron convergence average: 2.24\n"
     ]
    }
   ],
   "source": [
    "prob5to7(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
